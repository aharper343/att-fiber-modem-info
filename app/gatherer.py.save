import logging
import os
import re
import requests
from abc import ABC, abstractmethod
from bs4 import BeautifulSoup
from logging import getLogger
from datetime import timedelta
from datetime import datetime


logger = logging.getLogger(__name__)


class ModemConfig:
    url: str
    access_code: str

    def __init__(self, url: str, access_code: str):
        self.url = url
        self.access_code = access_code

    @staticmethod
    def from_env():
        return ModemConfig(
            url=os.getenv("MODEM_URL", "http://192.168.1.254"),
            access_code=os.getenv("MODEM_ACCESS_CODE", None)
        )
        
class ModemClient:

    def __init__(self, config: ModemConfig):
        self.config = config
        self.session = requests.Session()
        self.nonce = None
        self.logged_in = False

    def _fetch(self, path) -> requests.Response:
        full_url = f"{self.config.url}{path}"
        response = self.session.get(full_url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        nonce_tag = soup.find('input', {'name': 'nonce'})
        if nonce_tag:
            self.nonce = nonce_tag['value']
        return response


class DataGatherer(ABC):
    @abstractmethod
    def gather(self):
        pass

    @abstractmethod
    def getName(self) -> str:
        pass

    @abstractmethod
    def getApiName(self) -> str:
        pass


class ModemClientDataGatherer(DataGatherer):

    def __init__(self, client: ModemClient, uri: str, requires_login: bool = False):
        self.client = client
        self.uri = uri
        self.requires_login = requires_login
        self.logger = getLogger(self.__class__.__name__)

    def gather(self):
        response = self.client._fetch(self.uri)
        stats = self._parse_html(response.text)
        if not stats:
            self.logger.warning("No stats found.")
            return None
        data = self._map(stats)
        self.logger.info(f"Data -> {data}")
        return data

    def getName(self) -> str:
        return self.__class__.__name__
    
    def getApiName(self) -> str:
         return re.sub(r'(?<!^)(?=[A-Z])', '-', self.getName()).lower().replace('-gatherer', '')


    @abstractmethod
    def _map(self, stats: dict):
        pass

    def _parse_html(self, html):
        soup = BeautifulSoup(html, 'html.parser')
        return self._parse_soup(soup)

    def _parse_soup(self, soup):
        stats = {}
        # Find all tables and iterate rows to find known labels
        tables = soup.find_all('table')
        for table in tables:
            summary = table.get('summary', '')
            self.logger.debug(f"Parsing table with summary: {summary}")
            rows = table.find_all('tr')
            for row in rows:
                cols = row.find_all(['td', 'th'])
                if not cols:
                    continue
                
                # First column is usually the label
                label = cols[0].get_text(strip=True)
                if not label:
                    continue
                # Subsequent columns are values for Line 1, Line 2, etc.
                values = [c.get_text(strip=True) for c in cols[1:]]
                if not values:
                    continue
                if summary:
                    if summary not in stats:
                        stats[summary] = {}
                    data = stats[summary]
                    level = f'{summary}.'
                else:
                    data = stats
                    level = ''
                if label in stats:
                    logger.warning(f"Duplicate label found: {level}{label}, overwriting previous values.")
                data[label] = values
                logger.debug(f"Found {level}{label} -> {values}")
        return stats
    
    def _to_int(self, value: str) -> int:
        if not value:
            return None
        try:
            return int(value)
        except (ValueError, TypeError):
            return 0
        
    def _to_str(self, value: str) -> str:
        if not value:
            return None
        return str(value).strip()
    
    def _to_lower(self, value: str) -> str:
        if not value:
            return None
        return str(value).lower().strip()

    def _to_upper(self, value: str) -> str:
        if not value:
            return None
        return str(value).upper().strip()
    
    def _to_datetime(self, value: str):
        value = self._to_str(value)
        if not value:
            return None
        if 'T' in value and '-' in value and ':' in value:
            try:
                return datetime.strptime(value, "%Y-%m-%dT%H:%M:%S")
            except ValueError:
                logger.warning(f"Unable to parse datetime from value: {value}")
                return None
        elif ' ' in value and '/' in value and ':' in value:
            try:
                return datetime.strptime(value, "%Y/%m/%d %H:%M:%S")
            except ValueError:
                logger.warning(f"Unable to parse datetime from value: {value}")
                return None
        logger.warning(f"Unable to parse datetime from value: {value}")
        return None
    
        
    def _to_timedelta(self, value: str) -> timedelta:
        if not value:
            return None
        split = value.split(':')
        if len(split) <= 4:
            match tuple(map(float, split)):
                case (days, hours, minutes, seconds):
                    return timedelta(days=days, hours=hours, minutes=minutes, seconds=seconds)
                case (hours, minutes, seconds):
                    return timedelta(hours=hours, minutes=minutes, seconds=seconds)
                case (minutes, seconds):
                    return timedelta(minutes=minutes, seconds=seconds)
                case (seconds,):
                    return timedelta(seconds=seconds)
        logger.warning(f"Unable to parse timedelta from value: {value}")
        return None
    

class CachingDataGatherer(DataGatherer):

    def __init__(self, gatherer: DataGatherer, cache_duration: timedelta = timedelta(minutes=5)):
        self.gatherer = gatherer
        self.cache_duration = cache_duration
        self.logger = getLogger(self.__class__.__name__)
        self.cache = None
        self.last_update = None

    def gather(self):
        if self.cache is None or (self.last_update is not None and datetime.now() - self.last_update > self.cache_duration):
            self.logger.info("Cache expired or empty, gathering new data.")
            self.cache = self.gatherer.gather()
            self.last_update = datetime.now()
        else:
            self.logger.info("Returning cached data.")
        return self._cache
    
    def getName(self) -> str:
        return self.gatherer.getName()
    
    def getApiName(self) -> str:
        return self.gatherer.getApiName()
    
